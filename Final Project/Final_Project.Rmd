---
title: "Project-One-Group-3"
author: "Jasmine Dogu, Brian Wimmer, Christos Chen - Group 3"
date: "01/11/2021"
output:
  html_document:
    toc: yes
    toc_float: yes
    theme: paper
  pdf_document:
    toc: yes
---


```{r}
#Import packages 

library(tidyverse)
library(tidytext)
library(textdata)
install.packages("tidyselect")
library(tidyselect)
library(stringr)
library(DT)
install.packages("topicmodels")
library(tm)
library(plotly)
install.packages("LDAvis")
library(LDAvis)
library(topicmodels)

```



#Cleaning the Data 
```{r}
#reading in the dataset 
df <- read.csv("/cloud/project/Datasets/Text_Message_Classification.csv")
head(df,5)
```

```{r}
#Removing punctuation

df2 = df %>% 
  select(Message)

df2$Message <- (str_replace_all(df2$Message, "[[:punct:]]", " "))
head(df2)

df_xx = df2 %>%
  unnest_tokens(word, "Message")
head(df_xx)

df_xx <- df_xx %>% 
  anti_join(stop_words)

df_xx <- filter(df_xx, !str_detect(word, "na"))

```

```{r}

head(df_xx %>%
  count(df_xx$word, sort = TRUE), 20)

df_xx_count <- df_xx %>%
  count(word, sort=TRUE)

df_xx_count$word <- as.factor(df_xx_count$word) 
str(df_xx_count)

tokenword_plot = ggplotly(ggplot(
  data = head(df_xx_count, 30),
  aes(x = fct_reorder(word,n),
      y = n)
  ) + 
  geom_col() + 
  coord_flip()+
  theme_light()+
  xlab("Token Words")+
    ylab("Count")
  )
tokenword_plot

df_xx <- tibble(df_xx)

```

#Creating Unigrams and Bigrams 
```{r}
#Bigrams 
df_xx_ngrams_2 <- df2 %>%
  unnest_tokens(word, Message, token = "ngrams", n=2)

head(datatable(df_xx_ngrams_2), 20)

#Trigrams
df_xx_ngrams_3 <- df2 %>%
  unnest_tokens(word, Message, token = "ngrams", n=3)

head(datatable(df_xx_ngrams_3), 20)
```


```{r}
id <- rownames(df)
df_tf <- cbind(id=id, df)
df_tf
#------ Here, df = data_math_tf in Prof Wright's code 


#Placing everything in one column and adding "other id" back in


#Removing punctuation and NAs
df_tf$Message <- (str_replace_all(df_tf$Message, "[[:punct:]]", " "))

df_tf$Message <- (str_remove_all(df_tf$Message, "NA")) 
df_tf

#Counting of words, with ID

word_count_id <- df_tf %>%
  unnest_tokens(word, Message) %>%
  count(id, word, sort = TRUE)

head(word_count_id, 8)

total_words_id <- word_count_id %>% 
  group_by(id) %>% 
  summarize(total = sum(n))

head(total_words_id, 12)

journal_words_id <- left_join(word_count_id, total_words_id)

journal_words_id <- journal_words_id %>%
  bind_tf_idf(word, id, n)

datatable(journal_words_id)

```





# Exploratory Data Analysis


# Sentiment Analysis 


# Topic Modeling - Latent Dirichlet Allocation
```{r}
install.packages('topicmodels')
library(topicmodels)

data("AssociatedPress")
AssociatedPress


```

